{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Statistical Analysis of TDA derived signals\n",
    "\n",
    "## Incomplete for now\n",
    "\n",
    "following https://towardsdatascience.com/a-quick-introduction-on-granger-causality-testing-for-time-series-analysis-7113dc9420d2\n",
    "\n",
    "\n",
    "attempting to see if any of the results from the orderflow tda notebook seem to have a causal relationship to the actual price of btc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "\n",
    "from binance import Client\n",
    "import config as c \n",
    "\n",
    "key, secret = c.apis[1][0], c.apis[1][1]\n",
    "client = Client(key, secret)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "norm = np.loadtxt(\"orderflow_norms.txt\", dtype = float)\n",
    "def parse(date_str):\n",
    "    return datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "with open(\"y_sw.txt\", \"r\") as w:\n",
    "    y_sw = np.array([np.datetime64(parse(i.strip()[:-3])) for i in w.readlines()])\n",
    "\n",
    "\n",
    "columns = [\"Open Time\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\",\n",
    "            \"Close Time\", \"Quote Asset Volume\", \"Number of Trades\",\n",
    "            \"Taker Buy Base Volume\", \"Taker Buy Quote Asset Volume\",\n",
    "            \"Ignore\"]\n",
    "period = \"1h\"\n",
    "\n",
    "\n",
    "\n",
    "# df of norm, and any other stats to be plotted\n",
    "calced_df = pd.DataFrame(\n",
    "    {\n",
    "        \"norm\": norm[:,1][1:],\n",
    "    },\n",
    "    index = y_sw[1:]\n",
    ")\n",
    "\n",
    "# range of data to work with\n",
    "start = calced_df.index[0].replace(microsecond=0, second=0, minute=0)\n",
    "end = calced_df.index[-1].replace(microsecond=0, second=0, minute=0, hour = calced_df.index[-1].hour)\n",
    "idx = pd.date_range(start=start, end=end, freq = period)\n",
    "\n",
    "\n",
    "# reindex calced_df to be evenly spaces\n",
    "calced_df = calced_df.to_period(freq = period).groupby(calced_df.to_period(freq = period).index).mean().to_timestamp().reindex(idx, fill_value=0)\n",
    "\n",
    "\n",
    "\n",
    "# data to download from binance\n",
    "klines = client.get_historical_klines(\"BTCUSDT\", period, str(start.timestamp() * 1000-3600000), str(end.timestamp() * 1000))\n",
    "klines = [[float(i) for i in line] for line in klines ]\n",
    "k_df = pd.DataFrame(klines, columns = columns, index = idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "close_series = k_df[\"Close\"]\n",
    "norm_series = pd.Series(calced_df[\"norm\"].values/max(calced_df[\"norm\"].values), name = 'norm', index = idx)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "n_obs = 20\n",
    "# df_train, df_test = df[0:-n_obs], df[-n_obs:]\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(df):\n",
    "    result = adfuller(df.values)\n",
    "    print('ADF Statistics: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "        \n",
    "print('ADF Test: Close time series')\n",
    "adf_test(close_series)\n",
    "\n",
    "print('ADF Test: Norm time series')\n",
    "adf_test(norm_series)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ADF Test: Close time series\n",
      "ADF Statistics: -1.765038\n",
      "p-value: 0.397952\n",
      "Critical values:\n",
      "\t1%: -3.436\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "ADF Test: Norm time series\n",
      "ADF Statistics: -16.400192\n",
      "p-value: 0.000000\n",
      "Critical values:\n",
      "\t1%: -3.436\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# need to make df with differenced close values, ignore first value\n",
    "\n",
    "df = pd.concat([np.log(close_series.pct_change()+1), norm_series], axis=1)[1:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_train, df_test = df[0:-n_obs], df[-n_obs:]\n",
    "df_train_transformed = df_train\n",
    "\n",
    "print('ADF Test: Close time series')\n",
    "adf_test(df_train_transformed['Close'])\n",
    "\n",
    "print('ADF Test: Norm time series')\n",
    "adf_test(df_train_transformed['norm'])\n",
    "\n",
    "# reject null hypo, differenced time sreies is now stationary. now make df with differenced s&p and norm data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ADF Test: Close time series\n",
      "ADF Statistics: -32.815050\n",
      "p-value: 0.000000\n",
      "Critical values:\n",
      "\t1%: -3.437\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n",
      "ADF Test: Norm time series\n",
      "ADF Statistics: -16.219785\n",
      "p-value: 0.000000\n",
      "Critical values:\n",
      "\t1%: -3.437\n",
      "\t5%: -2.864\n",
      "\t10%: -2.568\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "model = VAR(df_train_transformed)\n",
    "for i in range(0, 10):\n",
    "    result = model.fit(i)\n",
    "    print('Lag Order =', i)\n",
    "    print('AIC : ', result.aic)\n",
    "    print('BIC : ', result.bic)\n",
    "    print('FPE : ', result.fpe)\n",
    "    print('HQIC: ', result.hqic, '\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Lag Order = 0\n",
      "AIC :  -14.94315041914671\n",
      "BIC :  -14.933730858819768\n",
      "FPE :  3.23796560516924e-07\n",
      "HQIC:  -14.939579315443227 \n",
      "\n",
      "Lag Order = 1\n",
      "AIC :  -15.46698025475953\n",
      "BIC :  -15.438700130843383\n",
      "FPE :  1.9176786672839083e-07\n",
      "HQIC:  -15.4562583172976 \n",
      "\n",
      "Lag Order = 2\n",
      "AIC :  -15.48881366213855\n",
      "BIC :  -15.4416443246421\n",
      "FPE :  1.8762631871166422e-07\n",
      "HQIC:  -15.470929364583183 \n",
      "\n",
      "Lag Order = 3\n",
      "AIC :  -15.482538860932696\n",
      "BIC :  -15.416451588357342\n",
      "FPE :  1.8880738550477022e-07\n",
      "HQIC:  -15.457480647419311 \n",
      "\n",
      "Lag Order = 4\n",
      "AIC :  -15.479278122040206\n",
      "BIC :  -15.394244121133502\n",
      "FPE :  1.894241265973748e-07\n",
      "HQIC:  -15.447034407071389 \n",
      "\n",
      "Lag Order = 5\n",
      "AIC :  -15.47375971322446\n",
      "BIC :  -15.369750118732684\n",
      "FPE :  1.904724692292414e-07\n",
      "HQIC:  -15.434318881566256 \n",
      "\n",
      "Lag Order = 6\n",
      "AIC :  -15.469465517502586\n",
      "BIC :  -15.346451391922228\n",
      "FPE :  1.9129234729533395e-07\n",
      "HQIC:  -15.422815924080338 \n",
      "\n",
      "Lag Order = 7\n",
      "AIC :  -15.464511463627055\n",
      "BIC :  -15.322463796955214\n",
      "FPE :  1.9224263647667048e-07\n",
      "HQIC:  -15.410641433420784 \n",
      "\n",
      "Lag Order = 8\n",
      "AIC :  -15.461937158708604\n",
      "BIC :  -15.300826868192276\n",
      "FPE :  1.927385137978602e-07\n",
      "HQIC:  -15.400834986647915 \n",
      "\n",
      "Lag Order = 9\n",
      "AIC :  -15.455652283353484\n",
      "BIC :  -15.275450213237757\n",
      "FPE :  1.9395411146936544e-07\n",
      "HQIC:  -15.387306234212016 \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# model 2 has least aic and bic, so thats probably the best model\n",
    "\n",
    "model.select_order(2)\n",
    "results = model.fit(maxlags=2, ic='aic')\n",
    "results.summary()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Summary of Regression Results   \n",
       "==================================\n",
       "Model:                         VAR\n",
       "Method:                        OLS\n",
       "Date:           Sun, 29, Aug, 2021\n",
       "Time:                     16:06:17\n",
       "--------------------------------------------------------------------\n",
       "No. of Equations:         2.00000    BIC:                   -15.4416\n",
       "Nobs:                     1051.00    HQIC:                  -15.4709\n",
       "Log likelihood:           5166.76    FPE:                1.87626e-07\n",
       "AIC:                     -15.4888    Det(Omega_mle):     1.85854e-07\n",
       "--------------------------------------------------------------------\n",
       "Results for equation Close\n",
       "===========================================================================\n",
       "              coefficient       std. error           t-stat            prob\n",
       "---------------------------------------------------------------------------\n",
       "const            0.000305         0.000234            1.302           0.193\n",
       "L1.Close        -0.012933         0.030926           -0.418           0.676\n",
       "L1.norm          0.000399         0.001905            0.209           0.834\n",
       "L2.Close        -0.007943         0.030936           -0.257           0.797\n",
       "L2.norm         -0.000577         0.001905           -0.303           0.762\n",
       "===========================================================================\n",
       "\n",
       "Results for equation norm\n",
       "===========================================================================\n",
       "              coefficient       std. error           t-stat            prob\n",
       "---------------------------------------------------------------------------\n",
       "const            0.044515         0.003748           11.878           0.000\n",
       "L1.Close        -0.020038         0.494696           -0.041           0.968\n",
       "L1.norm          0.750647         0.030468           24.637           0.000\n",
       "L2.Close        -0.782284         0.494849           -1.581           0.114\n",
       "L2.norm         -0.168182         0.030476           -5.519           0.000\n",
       "===========================================================================\n",
       "\n",
       "Correlation matrix of residuals\n",
       "            Close      norm\n",
       "Close    1.000000 -0.003191\n",
       "norm    -0.003191  1.000000\n",
       "\n"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "out = durbin_watson(results.resid)\n",
    "\n",
    "for col, val in zip(df.columns, out):\n",
    "    print(col, ':', round(val, 2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Close : 2.0\n",
      "norm : 1.99\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "maxlag=15\n",
    "test = 'ssr_chi2test'\n",
    "\n",
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    \n",
    "   \n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "grangers_causation_matrix(df_train_transformed, variables = df_train_transformed.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Close_x  norm_x\n",
       "Close_y   1.0000   0.382\n",
       "norm_y    0.0152   1.000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_x</th>\n",
       "      <th>norm_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close_y</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_y</th>\n",
       "      <td>0.0152</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "lag_order = results.k_ar\n",
    "print(lag_order)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df_input = df_train_transformed.values[-lag_order:]\n",
    "df_forecast = results.forecast(y=df_input, steps=n_obs)\n",
    "df_forecast = (pd.DataFrame(df_forecast, index=df_test.index, columns=df_test.columns + '_pred'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def invert_transformation(df, pred):\n",
    "    forecast = df_forecast.copy()\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        forecast[str(col)+'_pred'] = df[col].iloc[-1] + forecast[str(col)+'_pred'].cumsum()\n",
    "    return forecast\n",
    "output = invert_transformation(df_train, df_forecast)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "combined = pd.concat([output['norm_pred'], df_test['norm'], output['Close_pred'], df_test['Close']], axis=1)\n",
    "combined"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     norm_pred      norm  Close_pred     Close\n",
       "2020-02-16 21:00:00   0.092134  0.078472   -0.003377 -0.012611\n",
       "2020-02-16 22:00:00   0.152996  0.081920   -0.003087  0.002056\n",
       "2020-02-16 23:00:00   0.218035  0.037361   -0.002817  0.004192\n",
       "2020-02-17 00:00:00   0.284959  0.035954   -0.002541 -0.005162\n",
       "2020-02-17 01:00:00   0.352766  0.061903   -0.002263  0.003647\n",
       "2020-02-17 02:00:00   0.420992  0.077875   -0.001984 -0.002316\n",
       "2020-02-17 03:00:00   0.489417  0.108123   -0.001704  0.012125\n",
       "2020-02-17 04:00:00   0.557937  0.127203   -0.001424  0.004009\n",
       "2020-02-17 05:00:00   0.626504  0.134718   -0.001143 -0.005570\n",
       "2020-02-17 06:00:00   0.695093  0.120493   -0.000863 -0.000949\n",
       "2020-02-17 07:00:00   0.763693  0.062565   -0.000583 -0.001251\n",
       "2020-02-17 08:00:00   0.832298  0.054961   -0.000302 -0.003268\n",
       "2020-02-17 09:00:00   0.900906  0.078389   -0.000022 -0.006776\n",
       "2020-02-17 10:00:00   0.969516  0.072534    0.000259  0.002012\n",
       "2020-02-17 11:00:00   1.038125  0.128937    0.000539  0.001262\n",
       "2020-02-17 12:00:00   1.106736  0.119927    0.000819 -0.002135\n",
       "2020-02-17 13:00:00   1.175346  0.040601    0.001100  0.005045\n",
       "2020-02-17 14:00:00   1.243956  0.075107    0.001380 -0.001027\n",
       "2020-02-17 15:00:00   1.312566  0.226376    0.001661 -0.007914\n",
       "2020-02-17 16:00:00   1.381177  0.448031    0.001941 -0.010908"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_pred</th>\n",
       "      <th>norm</th>\n",
       "      <th>Close_pred</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-16 21:00:00</th>\n",
       "      <td>0.092134</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>-0.003377</td>\n",
       "      <td>-0.012611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 22:00:00</th>\n",
       "      <td>0.152996</td>\n",
       "      <td>0.081920</td>\n",
       "      <td>-0.003087</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16 23:00:00</th>\n",
       "      <td>0.218035</td>\n",
       "      <td>0.037361</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 00:00:00</th>\n",
       "      <td>0.284959</td>\n",
       "      <td>0.035954</td>\n",
       "      <td>-0.002541</td>\n",
       "      <td>-0.005162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 01:00:00</th>\n",
       "      <td>0.352766</td>\n",
       "      <td>0.061903</td>\n",
       "      <td>-0.002263</td>\n",
       "      <td>0.003647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 02:00:00</th>\n",
       "      <td>0.420992</td>\n",
       "      <td>0.077875</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 03:00:00</th>\n",
       "      <td>0.489417</td>\n",
       "      <td>0.108123</td>\n",
       "      <td>-0.001704</td>\n",
       "      <td>0.012125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 04:00:00</th>\n",
       "      <td>0.557937</td>\n",
       "      <td>0.127203</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>0.004009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 05:00:00</th>\n",
       "      <td>0.626504</td>\n",
       "      <td>0.134718</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>-0.005570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 06:00:00</th>\n",
       "      <td>0.695093</td>\n",
       "      <td>0.120493</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>-0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 07:00:00</th>\n",
       "      <td>0.763693</td>\n",
       "      <td>0.062565</td>\n",
       "      <td>-0.000583</td>\n",
       "      <td>-0.001251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 08:00:00</th>\n",
       "      <td>0.832298</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>-0.000302</td>\n",
       "      <td>-0.003268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 09:00:00</th>\n",
       "      <td>0.900906</td>\n",
       "      <td>0.078389</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.006776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 10:00:00</th>\n",
       "      <td>0.969516</td>\n",
       "      <td>0.072534</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.002012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 11:00:00</th>\n",
       "      <td>1.038125</td>\n",
       "      <td>0.128937</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 12:00:00</th>\n",
       "      <td>1.106736</td>\n",
       "      <td>0.119927</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>-0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 13:00:00</th>\n",
       "      <td>1.175346</td>\n",
       "      <td>0.040601</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.005045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 14:00:00</th>\n",
       "      <td>1.243956</td>\n",
       "      <td>0.075107</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>-0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 15:00:00</th>\n",
       "      <td>1.312566</td>\n",
       "      <td>0.226376</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>-0.007914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17 16:00:00</th>\n",
       "      <td>1.381177</td>\n",
       "      <td>0.448031</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>-0.010908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "rmse = mean_squared_error(combined['Close_pred'], combined['Close'], squared=False)\n",
    "mae = mean_absolute_error(combined['Close_pred'], combined['Close'])\n",
    "\n",
    "print('Forecast accuracy of Close')\n",
    "print('RMSE: ', round(rmse,2))\n",
    "print('MAE: ', round(mae,2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Forecast accuracy of Close\n",
      "RMSE:  0.01\n",
      "MAE:  0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tda': conda)"
  },
  "interpreter": {
   "hash": "fe7e40918e936608d3d372707ad407c82a45124dfe21f6d77866cbb39f6abe77"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}